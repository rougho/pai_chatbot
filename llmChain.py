
from langchain_community.llms import Ollama
from langchain_core.prompts import ChatPromptTemplate


# llm = Ollama(model="llama2")

# print(llm.invoke("how can langsmith help with testing?"))

# prompt = ChatPromptTemplate.from_messages([
#     ("system", "You are world class technical documentation writer."),
#     ("user", "{input}")
# ])

# chain = prompt | llm

# print(chain.invoke({"input": "how can langsmith help with testing?"}))
